{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauliana/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text_classification.py:89: UserWarning: `return_all_scores` is now deprecated,  if want a similar funcionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "def classify_text(text, classifier):\n",
    "    predicted_label = classifier(text)\n",
    "\n",
    "    # # Sort the list of dictionaries based on the 'score' in descending order\n",
    "    # sorted_data = sorted(predicted_label[0], key=lambda x: x['score'], reverse=True)\n",
    "    # return sorted_data[0]['label']\n",
    "    return predicted_label[0]['label']\n",
    "\n",
    "model = pipeline(\"text-classification\", model=\"helper_models/emo_clf/best-model\", return_all_scores=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empathetic Dialogue Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20408"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read data\n",
    "train_data = pd.read_csv('train_emo_prompt.tsv', sep='\\t')\n",
    "eval_data = pd.read_csv('valid_emo_prompt.tsv', sep='\\t')\n",
    "\n",
    "# combine data\n",
    "data = pd.concat([train_data, eval_data], axis=0)\n",
    "\n",
    "# change the header\n",
    "header = {'context': 'label', 'prompt': 'text'}\n",
    "data = data.rename(columns=header)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10089\n",
      "10319\n"
     ]
    }
   ],
   "source": [
    "plutchik = ['anticipating', 'joy', 'trust', 'fear', 'surprise', 'sad', 'disgust', 'anger']\n",
    "\n",
    "def filter_data(df, label):\n",
    "    # Define a dictionary to map the values\n",
    "    mapping = {\n",
    "        'anxious': 'anticipating',\n",
    "        'joyful': 'joy',\n",
    "        'content': 'joy',\n",
    "        'trusting': 'trust',\n",
    "        'afraid': 'fear',\n",
    "        'terrified': 'fear',\n",
    "        'surprised': 'surprise',\n",
    "        'lonely': 'sad',\n",
    "        'devastated': 'sad',\n",
    "        'disgusted': 'disgust',\n",
    "        'angry': 'anger',\n",
    "        'annoyed': 'anger',\n",
    "        'furious': 'anger'\n",
    "    }\n",
    "    # Replace values in the 'context' column using the dictionary\n",
    "    df['label']  = df['label'].replace(mapping)\n",
    "   \n",
    "   # get the data with plutchuik label\n",
    "    p_df = df[df['label'].isin(label)] \n",
    "\n",
    "    # get the data with no plutchuik label\n",
    "    np_df = df[~df['label'].isin(label)] \n",
    "\n",
    "    return p_df, np_df\n",
    "\n",
    "p_data, np_data = filter_data(data, plutchik)\n",
    "print(len(p_data))\n",
    "print(len(np_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "old_label = []\n",
    "new_label = []\n",
    "\n",
    "for i in range(len(np_data)):\n",
    "    # classify the text to get new label\n",
    "    label = classify_text(np_data.iloc[i]['text'], model)\n",
    "    text.append(np_data.iloc[i]['text'])\n",
    "    old_label.append(np_data.iloc[i]['label'])\n",
    "    new_label.append(label)\n",
    "\n",
    "# combine in one dataframe\n",
    "new_p_data = pd.DataFrame({\n",
    "    'label': new_label,\n",
    "    'text': text,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20408"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine with p_data\n",
    "new_data = pd.concat([p_data, new_p_data], axis=0)\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "new_data.to_csv(\"emo_plutchik_label.tsv\", \"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DailyDialog Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str(str):\n",
    "    str = str.replace(\" . \", \". \")\n",
    "    str = str.replace(\" , \", \", \")\n",
    "    str = str.replace(\" ? \", \"? \")\n",
    "    str = str.replace(\" ' \", \"'\")\n",
    "    str = str.replace(\" ’ \", \"'\")\n",
    "    return str\n",
    "\n",
    "def get_emotion(value):\n",
    "    mapping = {'0': 'other', '1': 'anger', '2': 'disgust', '3': 'fear', '4': 'happiness', '5': 'sad', '6': 'surprise'}\n",
    "    return mapping.get(str(value), 'Invalid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: Invalid \n",
      "Text:  OK, let's go and ask. \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td>The kitchen stinks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>I'll throw out the garbage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happiness</td>\n",
       "      <td>So Dick, how about getting some coffee for ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disgust</td>\n",
       "      <td>Coffee? I don't honestly like that kind of st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>other</td>\n",
       "      <td>Come on, you can at least try a little, besid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                               text\n",
       "0    disgust                               The kitchen stinks. \n",
       "1      other                       I'll throw out the garbage. \n",
       "2  happiness  So Dick, how about getting some coffee for ton...\n",
       "3    disgust   Coffee? I don't honestly like that kind of st...\n",
       "4      other   Come on, you can at least try a little, besid..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Open file\n",
    "path = '../datasets/raw/dailydialog/'\n",
    "text = open(path+'dialogues_text.txt', 'r')\n",
    "emo = open(path+'dialogues_emotion.txt', 'r')\n",
    "\n",
    "# read data\n",
    "data_text = []\n",
    "for line in text:\n",
    "    data_text.append(line)\n",
    "\n",
    "data_emo = []\n",
    "for line in emo:\n",
    "    data_emo.append(line)\n",
    "\n",
    "text = []\n",
    "label = []\n",
    "\n",
    "for i in range(len(data_text)):\n",
    "    split_text = data_text[i].split(\"__eou__\")\n",
    "    split_emo= data_emo[i].split(\" \")\n",
    "\n",
    "    for j in range(len(split_text)-1):\n",
    "        utt_label = get_emotion(split_emo[j])\n",
    "        utt_text = clean_str(split_text[j])\n",
    "        if utt_label == 'Invalid':\n",
    "            print(f\"Label: {utt_label} \\nText: {utt_text}\\n\")\n",
    "        else:\n",
    "            # print(f\"Label: {label} \\nText: {text}\\n\")\n",
    "            text.append(utt_text)\n",
    "            label.append(utt_label)\n",
    "\n",
    "dd_combine = pd.DataFrame({\n",
    "    'label': label,\n",
    "    'text': text,\n",
    "})\n",
    "\n",
    "dd_combine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plutchik's emotion wheel define happiness is derive from Joy and Trust.<br>\n",
    "From Daily Dialog datasets, except 'happiness' and 'other' is included in plutchik's primary emotion. Therefore, we will re-labelling only for data with those label with classifier we build before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disgust</td>\n",
       "      <td>I'll throw out the garbage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disgust</td>\n",
       "      <td>So Dick, how about getting some coffee for ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joy</td>\n",
       "      <td>Come on, you can at least try a little, besid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sad</td>\n",
       "      <td>Not for me, Dick.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anger</td>\n",
       "      <td>Are things still going badly with your housegu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0  disgust                       I'll throw out the garbage. \n",
       "1  disgust  So Dick, how about getting some coffee for ton...\n",
       "2      joy   Come on, you can at least try a little, besid...\n",
       "3      sad                                 Not for me, Dick. \n",
       "4    anger  Are things still going badly with your housegu..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the data with no plutchuik label\n",
    "np_dd = dd_combine[~dd_combine['label'].isin(plutchik)] \n",
    "np_dd.label.unique()\n",
    "\n",
    "np_text = []\n",
    "new_label = []\n",
    "\n",
    "for i in range(len(np_dd)):\n",
    "    # classify the text to get new label\n",
    "    label = classify_text(np_dd.iloc[i]['text'], model)\n",
    "    np_text.append(np_dd.iloc[i]['text'])\n",
    "    # old_label.append(np_dd.iloc[i]['label'])\n",
    "    new_label.append(label)\n",
    "\n",
    "# combine in one dataframe\n",
    "new_dd_np = pd.DataFrame({\n",
    "    'label': new_label,\n",
    "    'text': np_text,\n",
    "})\n",
    "new_dd_np.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98457"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102979"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data with plutchik label\n",
    "p_dd = dd_combine[dd_combine['label'].isin(plutchik)] \n",
    "\n",
    "# combine with classified non plutchik data\n",
    "new_dd_data = pd.concat([p_dd, new_dd_np], axis=0)\n",
    "len(new_dd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "new_dd_data.to_csv(\"dd_plutchik_label.tsv\", \"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topical-Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauliana/anaconda3/envs/py5/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mauliana/anaconda3/envs/py5/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "def classify_pbi(text, classifier):\n",
    "    predicted_label = classifier(text)\n",
    "    return predicted_label[0]['label']\n",
    "\n",
    "model = pipeline(\"text-classification\", model=\"helper_models/bg_clf/best-model\", return_all_scores=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Yeah, their services are good.'\n",
    "classify_pbi(text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the data\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_path = \"../datasets/raw/topicalchat/\"\n",
    "with open(json_path+\"train.json\", \"r\") as json_files:\n",
    "    data = json.load(json_files)\n",
    "\n",
    "# Flatten the nested structure\n",
    "flattened_data = []\n",
    "for key, value in data.items():\n",
    "    for content_item in value['content']:\n",
    "        flattened_data.append({\n",
    "            'conversation_id': key,\n",
    "            'article_url': value['article_url'],\n",
    "            'config': value['config'],\n",
    "            'message': content_item['message'],\n",
    "            'agent': content_item['agent'],\n",
    "            'sentiment': content_item['sentiment'],\n",
    "            'knowledge_source': content_item['knowledge_source'],\n",
    "            'turn_rating': content_item['turn_rating']\n",
    "        })\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(flattened_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FS1' 'FS2' 'FS3' 'Personal Knowledge' 'AS1' 'AS2' 'AS4' 'AS3']\n"
     ]
    }
   ],
   "source": [
    "df_explode = df.explode('knowledge_source')\n",
    "unique_values = df_explode['knowledge_source'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100749"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pk = df_explode[df_explode['knowledge_source'] == 'Personal Knowledge']\n",
    "fs = df_explode[df_explode['knowledge_source'] == 'FS2']\n",
    "df_concate = pd.concat([pk, fs])\n",
    "len(df_concate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_remove = ['conversation_id', 'article_url', 'config', 'agent', 'sentiment', 'turn_rating']\n",
    "df_shrink = df_concate.drop(columns= col_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelling the prepared data\n",
    "pb_text = []\n",
    "pb_label = []\n",
    "\n",
    "for i in range(len(df_shrink)):\n",
    "    # classify the text to get new label\n",
    "    label = classify_pbi(df_shrink.iloc[i]['message'], model)\n",
    "    pb_text.append(df_shrink.iloc[i]['message'])\n",
    "    pb_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:100749\n",
      "    Clean data size:90585\n",
      "\n",
      "Yes label: 24707\n",
      "No label: 65878\n"
     ]
    }
   ],
   "source": [
    "# combine in one dataframe\n",
    "tc_pb_data = pd.DataFrame({\n",
    "    'label': pb_label,\n",
    "    'text': pb_text,\n",
    "})\n",
    "\n",
    "print(f\"Data size:{len(tc_pb_data)}\")\n",
    "\n",
    "# remove duplicate\n",
    "tc_pb_clean = tc_pb_data.drop_duplicates()\n",
    "print(f\"    Clean data size:{len(tc_pb_clean)}\\n\")\n",
    "\n",
    "# check each label data size\n",
    "t = tc_pb_clean[tc_pb_clean['label']=='Yes']\n",
    "f = tc_pb_clean[tc_pb_clean['label']=='No']\n",
    "\n",
    "print(f\"Yes label: {len(t)}\")\n",
    "print(f\"No label: {len(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs1 = df_explode[df_explode['knowledge_source'] == 'FS1']\n",
    "fs3 = df_explode[df_explode['knowledge_source'] == 'FS3']\n",
    "fs_13 = pd.concat([fs1, fs3])\n",
    "df_fs = fs_13.drop(columns= col_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# labelling the prepared data\n",
    "pb2_text = []\n",
    "pb2_label = []\n",
    "\n",
    "for i in range(len(df_fs)):\n",
    "    # classify the text to get new label\n",
    "    label = classify_pbi(df_fs.iloc[i]['message'], model)\n",
    "    pb2_text.append(df_fs.iloc[i]['message'])\n",
    "    pb2_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size:101177\n",
      "    Clean data size:90585\n",
      "\n",
      "Yes label: 25286\n",
      "No label: 73598\n"
     ]
    }
   ],
   "source": [
    "# combine in one dataframe\n",
    "tc_pb_data2 = pd.DataFrame({\n",
    "    'label': pb2_label,\n",
    "    'text': pb2_text,\n",
    "})\n",
    "\n",
    "print(f\"Data size:{len(tc_pb_data2)}\")\n",
    "\n",
    "# remove duplicate\n",
    "tc_pb_clean2 = tc_pb_data2.drop_duplicates()\n",
    "print(f\"    Clean data size:{len(tc_pb_clean)}\\n\")\n",
    "\n",
    "# check each label data size\n",
    "t2 = tc_pb_clean2[tc_pb_clean2['label']=='Yes']\n",
    "f2 = tc_pb_clean2[tc_pb_clean2['label']=='No']\n",
    "\n",
    "print(f\"Yes label: {len(t2)}\")\n",
    "print(f\"No label: {len(f2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes total: 49993\n",
      "no total: 139476\n"
     ]
    }
   ],
   "source": [
    "yes_label = pd.concat([t, t2])\n",
    "no_label = pd.concat([f, f2])\n",
    "print(f\"yes total: {len(yes_label)}\")\n",
    "print(f\"no total: {len(no_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48817"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_no_label = no_label.sample(frac=0.35, random_state=42)\n",
    "split_no_label.reset_index(drop=True, inplace=True)\n",
    "len(split_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>I love to dance a lot. How about you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Yes</td>\n",
       "      <td>I would love to go there. I used to like readi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Yes</td>\n",
       "      <td>I used to in my childhood but not any more, I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Yes</td>\n",
       "      <td>On Paper and yes I do recall seeing Super-hero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Right me neither, there were so many good choi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48812</th>\n",
       "      <td>No</td>\n",
       "      <td>I would hope that it would force my NO Saints ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48813</th>\n",
       "      <td>No</td>\n",
       "      <td>Wow. In Japan they love baseball too. Many fan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48814</th>\n",
       "      <td>No</td>\n",
       "      <td>The one in Canada is the Toronto Raptors right...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48815</th>\n",
       "      <td>No</td>\n",
       "      <td>Ouch!  That's all I'll say.  I would have brok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48816</th>\n",
       "      <td>No</td>\n",
       "      <td>It was JFK, Washington and Jefferson. I believ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98810 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "2       Yes              I love to dance a lot. How about you?\n",
       "12      Yes  I would love to go there. I used to like readi...\n",
       "21      Yes  I used to in my childhood but not any more, I ...\n",
       "22      Yes  On Paper and yes I do recall seeing Super-hero...\n",
       "23      Yes  Right me neither, there were so many good choi...\n",
       "...     ...                                                ...\n",
       "48812    No  I would hope that it would force my NO Saints ...\n",
       "48813    No  Wow. In Japan they love baseball too. Many fan...\n",
       "48814    No  The one in Canada is the Toronto Raptors right...\n",
       "48815    No  Ouch!  That's all I'll say.  I would have brok...\n",
       "48816    No  It was JFK, Washington and Jefferson. I believ...\n",
       "\n",
       "[98810 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.concat([yes_label, split_no_label])\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98810"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to file\n",
    "final_data.to_csv(\"tc_personal_background.tsv\", \"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes label: 3227\n",
      "No label: 3789\n"
     ]
    }
   ],
   "source": [
    "# personal_background data overview\n",
    "data = pd.read_csv('personal_background.tsv', sep='\\t')\n",
    "data[\"label\"] = data[\"label\"].replace({True: 'Yes', False: 'No'})\n",
    "t = data[data['label']=='Yes']\n",
    "f = data[data['label']=='No']\n",
    "\n",
    "print(f\"Yes label: {len(t)}\")\n",
    "print(f\"No label: {len(f)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
