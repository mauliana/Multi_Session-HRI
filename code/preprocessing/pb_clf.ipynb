{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Personal Background Information Model Fine-tuning\n",
    "(helper_models) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>You sound like an animal lover too.  Any pets?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>I do love animals. We currently have a dog and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Same on the dog and cat.  The dog was a stray ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>We found our cat at the park one day, she was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>Awe!  I bet she is sweet.  What is her name?  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7011</th>\n",
       "      <td>No</td>\n",
       "      <td>It's a lot of fun. I play quarterback.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7012</th>\n",
       "      <td>No</td>\n",
       "      <td>what's your favorite team? Mine is the Saints</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7013</th>\n",
       "      <td>Yes</td>\n",
       "      <td>I liked watching the Saints win Superbowl XLIV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7014</th>\n",
       "      <td>Yes</td>\n",
       "      <td>I think we may go back this year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7015</th>\n",
       "      <td>No</td>\n",
       "      <td>We'll see. It's looking like a good year for a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7016 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0       No     You sound like an animal lover too.  Any pets?\n",
       "1       No  I do love animals. We currently have a dog and...\n",
       "2      Yes  Same on the dog and cat.  The dog was a stray ...\n",
       "3       No  We found our cat at the park one day, she was ...\n",
       "4       No  Awe!  I bet she is sweet.  What is her name?  ...\n",
       "...    ...                                                ...\n",
       "7011    No             It's a lot of fun. I play quarterback.\n",
       "7012    No      what's your favorite team? Mine is the Saints\n",
       "7013   Yes  I liked watching the Saints win Superbowl XLIV...\n",
       "7014   Yes                  I think we may go back this year \n",
       "7015    No  We'll see. It's looking like a good year for a...\n",
       "\n",
       "[7016 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../datasets/raw/personal_background.tsv', sep='\\t')\n",
    "data[\"label\"] = data[\"label\"].replace({True: 'Yes', False: 'No'})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, valid_df = train_test_split(data, test_size=0.20, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = train_df.label.unique()\n",
    "# Create id2label and label2id dictionaries\n",
    "id2label = {i: emotion for i, emotion in enumerate(label)}\n",
    "label2id = {emotion: i for i, emotion in enumerate(label)}\n",
    "\n",
    "train_text = train_df.text.values\n",
    "train_label = [label2id[label] for label in train_df.label.values]\n",
    "\n",
    "eval_text = valid_df.text.values\n",
    "eval_label = [label2id[label] for label in valid_df.label.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodings(texts, tokenizer):\n",
    "    encoded_data = tokenizer(\n",
    "        [text for text in texts],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt',\n",
    "        max_length=64\n",
    "    )\n",
    "    return encoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauliana/anaconda3/envs/py3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "train_encoding = encodings(train_text, tokenizer)\n",
    "eval_encoding = encodings(eval_text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.encodings['input_ids'][idx],\n",
    "            'attention_mask': self.encodings['attention_mask'][idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "train_dataset = CustomDataset(train_encoding, train_label)\n",
    "eval_dataset = CustomDataset(eval_encoding, eval_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2, id2label=id2label, label2id=label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load('recall')\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    acc_score = accuracy.compute(predictions=predictions, references=labels)\n",
    "    r_score = recall.compute(predictions=predictions, references=labels, average='macro')\n",
    "    p_score = precision.compute(predictions=predictions, references=labels, average='macro')\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy':round(acc_score['accuracy'], 2),\n",
    "        'precision':round(p_score['precision'], 2),\n",
    "        'recall':round(r_score['recall'], 2),\n",
    "        'f1':round(f1_score['f1'], 2)\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/880 [00:00<?, ?it/s]You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                 \n",
      "  6%|▌         | 50/880 [00:32<05:18,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6151394248008728, 'eval_accuracy': 0.68, 'eval_precision': 0.68, 'eval_recall': 0.68, 'eval_f1': 0.68, 'eval_runtime': 3.3877, 'eval_samples_per_second': 414.435, 'eval_steps_per_second': 6.494, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 11%|█▏        | 100/880 [00:54<04:51,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6062088012695312, 'eval_accuracy': 0.69, 'eval_precision': 0.69, 'eval_recall': 0.69, 'eval_f1': 0.69, 'eval_runtime': 3.0898, 'eval_samples_per_second': 454.4, 'eval_steps_per_second': 7.12, 'epoch': 1.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 17%|█▋        | 150/880 [01:16<04:33,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6003609299659729, 'eval_accuracy': 0.69, 'eval_precision': 0.69, 'eval_recall': 0.69, 'eval_f1': 0.69, 'eval_runtime': 4.0762, 'eval_samples_per_second': 344.441, 'eval_steps_per_second': 5.397, 'epoch': 1.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 23%|██▎       | 200/880 [01:38<04:12,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6344714164733887, 'eval_accuracy': 0.68, 'eval_precision': 0.69, 'eval_recall': 0.68, 'eval_f1': 0.68, 'eval_runtime': 2.9364, 'eval_samples_per_second': 478.129, 'eval_steps_per_second': 7.492, 'epoch': 2.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 28%|██▊       | 250/880 [02:02<03:55,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6115859746932983, 'eval_accuracy': 0.69, 'eval_precision': 0.69, 'eval_recall': 0.69, 'eval_f1': 0.69, 'eval_runtime': 5.9203, 'eval_samples_per_second': 237.151, 'eval_steps_per_second': 3.716, 'epoch': 2.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 34%|███▍      | 300/880 [02:25<03:36,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6319335699081421, 'eval_accuracy': 0.69, 'eval_precision': 0.69, 'eval_recall': 0.69, 'eval_f1': 0.69, 'eval_runtime': 3.3596, 'eval_samples_per_second': 417.908, 'eval_steps_per_second': 6.548, 'epoch': 3.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 40%|███▉      | 350/880 [02:47<03:20,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6404987573623657, 'eval_accuracy': 0.69, 'eval_precision': 0.69, 'eval_recall': 0.69, 'eval_f1': 0.69, 'eval_runtime': 3.0057, 'eval_samples_per_second': 467.105, 'eval_steps_per_second': 7.319, 'epoch': 3.98}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 45%|████▌     | 400/880 [03:08<02:59,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6731035113334656, 'eval_accuracy': 0.68, 'eval_precision': 0.68, 'eval_recall': 0.68, 'eval_f1': 0.68, 'eval_runtime': 2.9526, 'eval_samples_per_second': 475.516, 'eval_steps_per_second': 7.451, 'epoch': 4.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 51%|█████     | 450/880 [03:30<02:43,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7515609860420227, 'eval_accuracy': 0.66, 'eval_precision': 0.67, 'eval_recall': 0.66, 'eval_f1': 0.66, 'eval_runtime': 2.9635, 'eval_samples_per_second': 473.763, 'eval_steps_per_second': 7.424, 'epoch': 5.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 500/880 [03:49<02:27,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4998, 'learning_rate': 8.636363636363637e-06, 'epoch': 5.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 57%|█████▋    | 500/880 [03:53<02:27,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.750919759273529, 'eval_accuracy': 0.67, 'eval_precision': 0.67, 'eval_recall': 0.67, 'eval_f1': 0.67, 'eval_runtime': 3.0534, 'eval_samples_per_second': 459.811, 'eval_steps_per_second': 7.205, 'epoch': 5.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 62%|██████▎   | 550/880 [04:38<02:10,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.790925920009613, 'eval_accuracy': 0.67, 'eval_precision': 0.67, 'eval_recall': 0.67, 'eval_f1': 0.67, 'eval_runtime': 3.1059, 'eval_samples_per_second': 452.046, 'eval_steps_per_second': 7.083, 'epoch': 6.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 68%|██████▊   | 600/880 [05:01<02:20,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8316775560379028, 'eval_accuracy': 0.65, 'eval_precision': 0.65, 'eval_recall': 0.65, 'eval_f1': 0.65, 'eval_runtime': 3.0719, 'eval_samples_per_second': 457.048, 'eval_steps_per_second': 7.162, 'epoch': 6.82}\n",
      "{'train_runtime': 301.854, 'train_samples_per_second': 185.918, 'train_steps_per_second': 2.915, 'train_loss': 0.46509509086608886, 'epoch': 6.82}\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback, IntervalStrategy\n",
    "\n",
    "batch_size = 64\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"results-bg-10\",\n",
    "    learning_rate=2e-5,\n",
    "    seed= 42,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    eval_steps = 50,\n",
    "    report_to=\"tensorboard\",\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=2,\n",
    "    logging_dir='results-bg-10/logs',\n",
    "    metric_for_best_model = 'f1',\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "early_stop = EarlyStoppingCallback(2, 1.0)\n",
    "# early_stop = EarlyStoppingCallback(early_stopping_patience=3)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(output_dir='results-bg-10/best-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: No\n",
      "Class Probabilities:\n",
      "No: 0.5286\n",
      "Yes: 0.4714\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "# Set the logging level to WARNING or higher to suppress INFO messages\n",
    "logging.getLogger(\"transformers\").setLevel(logging.WARNING)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained('results-bg-10/best-model')\n",
    "\n",
    "new_text = \"Both are excellent technology they are helpful in many ways. For the security purpose both are super.\"\n",
    "inputs = tokenizer(new_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "probabilities = torch.softmax(logits, dim=1)\n",
    "predicted_class_index = torch.argmax(probabilities, dim=1).item()\n",
    "\n",
    "class_labels = [\"Yes\", \"No\"]\n",
    "\n",
    "predicted_class = class_labels[predicted_class_index]\n",
    "predicted_probabilities = probabilities[0].tolist()\n",
    "\n",
    "print(\"Predicted Class:\", predicted_class)\n",
    "print(\"Class Probabilities:\")\n",
    "# for label, prob in zip(class_labels, predicted_probabilities):\n",
    "#     print(f\"{label}: {prob:.4f}\")\n",
    "sorted_probabilities = sorted(\n",
    "    zip(class_labels, predicted_probabilities),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for label, prob in sorted_probabilities:\n",
    "    print(f\"{label}: {prob:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
